{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7053688e-4ff4-4980-806b-0ab6f2befb9f",
   "metadata": {},
   "source": [
    "## Semantic Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a9d2e8-ae81-4de9-a13f-89a74eefef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "import cmlreaders as cml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import gensim\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ab5d74-07f5-4467-a035-d7e8dd21c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_encoding_words(df_select):\n",
    "    all_words = []\n",
    "    spanish_subs = ['R1039M', 'R1070T', 'R1094T', 'R1134T', 'R1331T', 'R1461T', 'R1499T']\n",
    "\n",
    "    for _, row in tqdm(df_select.iterrows()):\n",
    "        # only english subjects\n",
    "        if row.subject in spanish_subs or (row.experiment == 'pyFR' and row.subject[:2] not in ['UP', 'TJ', 'CP', 'BW', 'CH']):\n",
    "            continue\n",
    "        \n",
    "        reader = cml.CMLReader(row.subject, row.experiment, row.session, row.localization, row.montage)\n",
    "        \n",
    "        try:\n",
    "            evs = reader.load('events')\n",
    "\n",
    "            # select encoding events\n",
    "            evs = evs[evs['type'] == 'WORD']\n",
    "\n",
    "            if row.experiment == 'pyFR':\n",
    "                words = evs['item'].unique()\n",
    "            else:\n",
    "                words = evs['item_name'].unique()\n",
    "\n",
    "            all_words.extend(list(words))\n",
    "\n",
    "        except BaseException as e:\n",
    "            continue\n",
    "\n",
    "    return np.unique(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e8d8b8d-e5af-4264-a8bb-6ca68692297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vector_representation(w, model, toggle):\n",
    "    if toggle:\n",
    "        try:\n",
    "            wv = model[w.upper()]\n",
    "            return True, wv\n",
    "        except KeyError:\n",
    "            return False, None\n",
    "    else:\n",
    "        try:\n",
    "            wv = model[w.lower()]\n",
    "            return True, wv\n",
    "        except KeyError:\n",
    "            return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4da61d8e-1f2d-49a9-a505-39b815291e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_semantic_similarities(all_words, model):\n",
    "    sem_sim = []\n",
    "    for w1, w2 in tqdm(itertools.combinations(all_words, 2)):\n",
    "        # vector representations\n",
    "        toggle1, wv1 = find_vector_representation(w1, model, True)           # uppercase\n",
    "        if not toggle1:\n",
    "            toggle1, wv1 = find_vector_representation(w1, model, False)      # lowercase\n",
    "\n",
    "        toggle2, wv2 = find_vector_representation(w2, model, True)          # uppercase\n",
    "        if not toggle2:\n",
    "            toggle2, wv2 = find_vector_representation(w2, model, False)     # lowercase\n",
    "\n",
    "        if toggle1 and toggle2:\n",
    "            # cosine similarity\n",
    "            cos_sim = np.dot(wv1, wv2) / (np.linalg.norm(wv1) * np.linalg.norm(wv2))\n",
    "\n",
    "            # store both directions\n",
    "            sem_sim.append((w1, w2, cos_sim))\n",
    "            sem_sim.append((w2, w1, cos_sim))\n",
    "        else:\n",
    "            print(w1, w2)\n",
    "\n",
    "    return pd.DataFrame(sem_sim, columns=['word_i', 'word_j', 'cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2b92aa-83ee-4373-897f-eaeb11d91faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cml.get_data_index()\n",
    "\n",
    "df_intrac = df[df.experiment.isin(['FR1', 'pyFR', 'IFR1'])]\n",
    "df_scalp = df[(df['experiment'] == 'ltpFR2') & (df['session'] != 23)]\n",
    "\n",
    "df_select = pd.concat([df_intrac, df_scalp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341fb324-3039-478b-a503-695a45f0431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff46bc4180540ae87f6cf1d933c0d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_words = find_all_encoding_words(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b4002f-b412-45a2-8fac-4f8350562b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9524a477-9e58-436d-b262-47a8238207d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147bdb7cade1403eb91632f61bf47c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sem_sim = generate_semantic_similarities(all_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2e7230e-4ac5-422b-8ec7-10c9618fe186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_sim.to_csv('semantic_cml.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bids",
   "language": "python",
   "name": "bids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
