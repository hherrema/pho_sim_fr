{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7053688e-4ff4-4980-806b-0ab6f2befb9f",
   "metadata": {},
   "source": [
    "## Semantic Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a9d2e8-ae81-4de9-a13f-89a74eefef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "import cmlreaders as cml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import gensim\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e10854-0c77-401a-b134-b160312485a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cml.get_data_index('ltp')\n",
    "df_select = df[(df.experiment == 'ltpFR2') & (df.session != 23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f0695b-892f-4852-b377-92f5b7d30b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all words (encoding and recalls)\n",
    "def find_all_words(df_select):\n",
    "    all_words = []\n",
    "    for _, row in tqdm(df_select.iterrows()):\n",
    "        reader = cml.CMLReader(row.subject, row.experiment, row.session)\n",
    "        \n",
    "        try:\n",
    "            evs = reader.load('events')\n",
    "            \n",
    "            # select encoding and recall events\n",
    "            evs = evs[evs['type'].isin(['WORD', 'REC_WORD'])]\n",
    "            words = evs['item_name'].unique()\n",
    "                \n",
    "            all_words.extend(list(words))\n",
    "            #all_words.extend([x for x in words if '<' not in x and '>' not in x])       # remove vocalizations\n",
    "            \n",
    "        except BaseException as e:\n",
    "            continue\n",
    "            \n",
    "    return np.unique(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8d8b8d-e5af-4264-a8bb-6ca68692297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vector_representation(w, model, toggle):\n",
    "    if toggle:\n",
    "        try:\n",
    "            wv = model[w.upper()]\n",
    "            return True, wv\n",
    "        except KeyError:\n",
    "            return False, None\n",
    "    else:\n",
    "        try:\n",
    "            wv = model[w.lower()]\n",
    "            return True, wv\n",
    "        except KeyError:\n",
    "            return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da61d8e-1f2d-49a9-a505-39b815291e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_semantic_similarities(all_words, model):\n",
    "    sem_sim = []\n",
    "    for w1, w2 in tqdm(itertools.combinations(all_words, 2)):\n",
    "        # vector representations\n",
    "        toggle1, wv1 = find_vector_representation(w1, model, True)           # uppercase\n",
    "        if not toggle1:\n",
    "            toggle1, wv1 = find_vector_representation(w1, model, False)      # lowercase\n",
    "\n",
    "        toggle2, wv2 = find_vector_representation(w2, model, True)          # uppercase\n",
    "        if not toggle2:\n",
    "            toggle2, wv2 = find_vector_representation(w2, model, False)     # lowercase\n",
    "\n",
    "        if toggle1 and toggle2:\n",
    "            # cosine similarity\n",
    "            cos_sim = np.dot(wv1, wv2) / (np.linalg.norm(wv1) * np.linalg.norm(wv2))\n",
    "\n",
    "            # store both directions\n",
    "            sem_sim.append((w1, w2, cos_sim))\n",
    "            sem_sim.append((w2, w1, cos_sim))\n",
    "        else:\n",
    "            #print(w1, w2)\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(sem_sim, columns=['word_i', 'word_j', 'cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbad9fb9-1eff-4d70-9606-5c978adc2c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e26ca48aff4909b1bea356fd5a74ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_words = find_all_words(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5843bff-fd80-48b9-8d91-2ff5101b7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205627f7-d0f5-4e14-be19-af130f331d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc79fc7cf8d4ab088057064b6902293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sem_sim = generate_semantic_similarities(all_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2e7230e-4ac5-422b-8ec7-10c9618fe186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_sim.to_csv('semantic_cml.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bids",
   "language": "python",
   "name": "bids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
